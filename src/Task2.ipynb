{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For imputing missing values for level_binary\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for predicting\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for hyperparameter optimization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for feature selection\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC, LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_data = pd.read_csv(\"forecasting_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8421, 18)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>y</th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level</th>\n",
       "      <th>level_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/13/2004</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>943</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>867.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/10/2004</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>919</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>704.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.9612</td>\n",
       "      <td>Low</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/21/2004</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>1221</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>626.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1.0919</td>\n",
       "      <td>High</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/12/2004</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1.0479</td>\n",
       "      <td>High</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/14/2004</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>1377</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>54.1</td>\n",
       "      <td>0.8003</td>\n",
       "      <td>High</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time     y  co_gt   nhmc  c6h6      s2    nox     s3  \\\n",
       "0  10/13/2004  20:00:00   943 -200.0 -200.0   7.2   867.0 -200.0  834.0   \n",
       "1   8/10/2004   3:00:00   919    0.5 -200.0   3.9   704.0 -200.0  861.0   \n",
       "2   6/21/2004   8:00:00  1221    3.7 -200.0  23.3  1386.0    NaN  626.0   \n",
       "3   7/12/2004  12:00:00  1024    2.1 -200.0  12.1  1052.0  183.0  779.0   \n",
       "4  12/14/2004  12:00:00  1377    4.4 -200.0  21.7  1342.0  786.0  499.0   \n",
       "\n",
       "     no2      s4      s5     t    rh      ah level  level_binary  \n",
       "0 -200.0  1314.0   891.0  14.8  57.3  0.9603   NaN           NaN  \n",
       "1 -200.0  1603.0   860.0  24.4  65.0  1.9612   Low          -1.0  \n",
       "2  109.0  2138.0     NaN  23.3  38.6  1.0919  High           1.0  \n",
       "3    NaN  1690.0   952.0  28.5  27.3  1.0479  High           1.0  \n",
       "4  206.0  1546.0  2006.0  12.9  54.1  0.8003  High           1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am making the assumption that the value of y given is 6 hours ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Low', 'High', 'Very low', 'Moderate', 'Very High'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I have made the assumption that the difference between all the levels are the same. \n",
    "reg_data[\"level\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_data[\"level_binary\"] = reg_data[\"level\"].map( {'Very low': -2, 'Low':-1, 'moderate':0, 'High':1, 'Very High':2 } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_data['hour'] = reg_data['time'].apply(lambda item: int(item.split(\":\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>y</th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level</th>\n",
       "      <th>level_binary</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/13/2004</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>943</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>867.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/10/2004</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>919</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>704.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.9612</td>\n",
       "      <td>Low</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/21/2004</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>1221</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>626.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1.0919</td>\n",
       "      <td>High</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/12/2004</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1.0479</td>\n",
       "      <td>High</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/14/2004</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>1377</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>54.1</td>\n",
       "      <td>0.8003</td>\n",
       "      <td>High</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time     y  co_gt   nhmc  c6h6      s2    nox     s3  \\\n",
       "0  10/13/2004  20:00:00   943 -200.0 -200.0   7.2   867.0 -200.0  834.0   \n",
       "1   8/10/2004   3:00:00   919    0.5 -200.0   3.9   704.0 -200.0  861.0   \n",
       "2   6/21/2004   8:00:00  1221    3.7 -200.0  23.3  1386.0    NaN  626.0   \n",
       "3   7/12/2004  12:00:00  1024    2.1 -200.0  12.1  1052.0  183.0  779.0   \n",
       "4  12/14/2004  12:00:00  1377    4.4 -200.0  21.7  1342.0  786.0  499.0   \n",
       "\n",
       "     no2      s4      s5     t    rh      ah level  level_binary  hour  \n",
       "0 -200.0  1314.0   891.0  14.8  57.3  0.9603   NaN           NaN    20  \n",
       "1 -200.0  1603.0   860.0  24.4  65.0  1.9612   Low          -1.0     3  \n",
       "2  109.0  2138.0     NaN  23.3  38.6  1.0919  High           1.0     8  \n",
       "3    NaN  1690.0   952.0  28.5  27.3  1.0479  High           1.0    12  \n",
       "4  206.0  1546.0  2006.0  12.9  54.1  0.8003  High           1.0    12  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -200.,    nan,   260.,   226.,   698.,   299.,    95.,   391.,\n",
       "         169.,   205.,   234.,    78.,   112.,   277.,   145.,    63.,\n",
       "          29.,   235.,   259.,    66.,   802.,   114.,   160.,    94.,\n",
       "         236.,    48.,   685.,    67.,   196.,    59.,   524.,    47.,\n",
       "          43.,    87.,   194.,   325.,    58.,   475.,    68.,    53.,\n",
       "         141.,    23.,   193.,   151.,    55.,    32.,   181.,   148.,\n",
       "         203.,   368.,   179.,    49.,    61.,    40.,    34.,    56.,\n",
       "         336.,   212.,    39.,    98.,   798.,   265.,   434.,    44.,\n",
       "          52.,   346.,   183.,   238.,     9.,   128.,   538.,   116.,\n",
       "          74.,    31.,   542.,   221.,   143.,   284.,   219.,   216.,\n",
       "          62.,   222.,    88.,   102.,   446.,   152.,   118.,   415.,\n",
       "         156.,    76.,   267.,   207.,   134.,   454.,   559.,    26.,\n",
       "         200.,   202.,    50.,   159.,   126.,   157.,   136.,    33.,\n",
       "         109.,    64.,   565.,    75.,   743.,    65.,    25.,   173.,\n",
       "         633.,    71.,   332.,   252.,    96.,    10.,   283.,   214.,\n",
       "         437.,   305.,   272.,    38.,    20.,   188.,   208.,   297.,\n",
       "         251.,   470.,   451.,   230.,   111.,   386.,   140.,   706.,\n",
       "         535.,   592.,   639.,   254.,   401.,    84.,   100.,   209.,\n",
       "         544.,   115.,   155.,   204.,   197.,   426.,   787.,   695.,\n",
       "         133.,   509.,    36.,   199.,   383.,    27.,   642.,   218.,\n",
       "          14.,    41.,   776.,    70.,    35.,   154.,    30.,   365.,\n",
       "         168.,    17.,    85.,   137.,   816.,   276.,    42.,   372.,\n",
       "         110.,   166.,   880.,   759.,   425.,   105.,   150.,   210.,\n",
       "         692.,   319.,   301.,    97.,   486.,   394.,   255.,   174.,\n",
       "         405.,   343.,    79.,    86.,   516.,   122.,   506.,   161.,\n",
       "         101.,   231.,   840.,     7.,   271.,   624.,   830.,   589.,\n",
       "          92.,   710.,    57.,   242.,   135.,   164.,   644.,    45.,\n",
       "         664.,   245.,   468.,   503.,   458.,   366.,   337.,   224.,\n",
       "          91.,   261.,   655.,  1189.,   339.,   790.,   424.,   459.,\n",
       "         237.,    46.,   120.,   588.,   104.,   171.,   220.,   737.,\n",
       "         778.,   176.,    72.,   797.,   374.,   108.,    80.,   206.,\n",
       "         534.,   304.,   274.,   119.,   334.,   536.,   754.,    21.,\n",
       "          93.,    16.,   184.,    73.,   300.,   586.,    18.,   165.,\n",
       "         467.,   185.,    19.,   294.,   721.,   438.,   367.,    54.,\n",
       "         144.,   322.,    69.,   232.,   228.,   472.,   191.,    51.,\n",
       "         247.,   660.,   512.,   457.,    82.,    83.,   248.,   658.,\n",
       "          81.,   657.,   465.,   275.,   553.,   233.,   804.,   635.,\n",
       "         511.,   375.,   345.,   270.,   189.,    89.,   211.,    60.,\n",
       "         146.,   541.,   201.,   577.,  1129.,   138.,   172.,   106.,\n",
       "         127.,   227.,   341.,   178.,   449.,   308.,   285.,   347.,\n",
       "         481.,   523.,    28.,   163.,   180.,   124.,   824.,   461.,\n",
       "         452.,   139.,   485.,   669.,   501.,    77.,   377.,   353.,\n",
       "         293.,   263.,   278.,   422.,   435.,   190.,   974.,   239.,\n",
       "          22.,   350.,   340.,   131.,   460.,   132.,   584.,    99.,\n",
       "         262.,   327.,   478.,   836.,   279.,   357.,   307.,   735.,\n",
       "         117.,   585.,   926.,   546.,   618.,   575.,   436.,   149.,\n",
       "          11.,   195.,   349.,   555.,   358.,   411.,   258.,  1042.,\n",
       "        1084.,   483.,   215.,   597.,   832.,   899.,   295.,   682.,\n",
       "         268.,   808.,   130.,   303.,   113.,   167.,   783.,   609.,\n",
       "         445.,   324.,   240.,   505.,   318.,   872.,   103.,   678.,\n",
       "         162.,   306.,   256.,   192.,   333.,   456.,   170.,   388.,\n",
       "         320.,   599.,    24.,   177.,   312.,   649.,     8.,   129.,\n",
       "         125.,   344.,   321.,   556.,   296.,   680.,   147.,   269.])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if variable is categorical\n",
    "reg_data['nhmc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_data = reg_data.drop(['date', 'time', 'level'], axis = 1)\n",
    "#y = reg_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_data, test_data = train_test_split(encoded_data, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing `level_binary` using classification as there is high correlation between some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setting up training data\n",
    "# train = X_train[np.invert(X_train.isnull()['level_binary'])]\n",
    "# train_X = train.drop(['level_binary'], axis = 1)\n",
    "# train_y = train['level_binary']\n",
    "\n",
    "# data_imputer = Imputer()\n",
    "# train_X_imp = data_imputer.fit_transform(train_X)\n",
    "\n",
    "# train_X = pd.DataFrame(train_X_imp, columns=train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #setting up predicting data\n",
    "# predict = X_train[X_train.isnull()['level_binary']]\n",
    "# predict_X = predict.drop(['level_binary'], axis = 1)\n",
    "# data_imputer = Imputer()\n",
    "# predict_X_imp = data_imputer.fit_transform(predict_X)\n",
    "# predict_X = pd.DataFrame(predict_X_imp, columns=predict_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developing model to predict `level_binary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gbt = GradientBoostingClassifier()\n",
    "# cross_val_score(gbt, train_X, train_y, cv=3)\n",
    "# #array([ 0.99086022,  0.99193548,  0.99301075])\n",
    "# gbt.fit(train_X, train_y)\n",
    "# predict_y = gbt.predict(predict_X)\n",
    "# cbind = pd.concat([predict_X.head().reset_index(drop=True), pd.DataFrame(predict_y, columns=[\"label\"]).head()], axis=1)\n",
    "# predict_X.head()\n",
    "# pd.DataFrame(predict_y, columns=[\"label\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_label(data, fit = False):\n",
    "    \n",
    "    # Data with level_binary\n",
    "    train = data[np.invert(data.isnull()['level_binary'])]\n",
    "    data_imputer = Imputer()\n",
    "    train_imp = data_imputer.fit_transform(train)\n",
    "    train = pd.DataFrame(train_imp, columns=train.columns)\n",
    "    target_train = train['y']\n",
    "    \n",
    "    \n",
    "    # Data missing level_binary\n",
    "    predict = data[data.isnull()['level_binary']]\n",
    "    predict_X = predict.drop(['level_binary', 'y'], axis = 1)\n",
    "    target_predict = predict['y']\n",
    "    predict_X_imp = data_imputer.fit_transform(predict_X)\n",
    "    predict_X = pd.DataFrame(predict_X_imp, columns=predict_X.columns)\n",
    "    \n",
    "    if fit:\n",
    "        #Preparing data to train\n",
    "        train_X = train.drop(['level_binary', 'y'], axis = 1)\n",
    "        train_y = train['level_binary']\n",
    "        \n",
    "        #Fit model\n",
    "        gbt = GradientBoostingClassifier()\n",
    "        gbt.fit(train_X, train_y)\n",
    "        \n",
    "        #Save model\n",
    "        save_classifier = open(\"predict_level.pickle\", \"wb\")\n",
    "        pickle.dump(gbt, save_classifier)\n",
    "        save_classifier.close()\n",
    "        \n",
    "        #Make predictions\n",
    "        predict_y = gbt.predict(predict_X)\n",
    "        \n",
    "        # Removing target variable from initial dataframe\n",
    "        train.drop(['y'], inplace=True, axis = 1)\n",
    "    else:\n",
    "        train.drop(['y'], inplace=True, axis = 1)\n",
    "        #Load saved model\n",
    "        classifier_f = open(\"predict_level.pickle\", \"rb\")\n",
    "        gbt = pickle.load(classifier_f)\n",
    "        classifier_f.close()\n",
    "        \n",
    "        #Make predictions\n",
    "        predict_y = gbt.predict(predict_X)\n",
    "    \n",
    "    #Concatenate the label with remaining data\n",
    "    predict_imputed = pd.concat([predict_X.reset_index(drop=True),\n",
    "                                 pd.DataFrame(predict_y, columns=[\"level_binary\"])], axis=1)\n",
    "    \n",
    "    #Combine \n",
    "    X_data = pd.concat([train.reset_index(drop=True), predict_imputed], axis=0, ignore_index=True)\n",
    "    \n",
    "    y_data = pd.concat([target_train.reset_index(drop=True), target_predict], axis=0, ignore_index=True)\n",
    "    \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = impute_label(train_data, fit=True)\n",
    "X_val, y_val = impute_label(val_data)\n",
    "X_test, y_test = impute_label(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1a554358>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEuCAYAAACKz7VmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCQ1DAZJUuP/A99FfNy/NR54AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1a5543c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.isnull().sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a19fdd208>"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEuCAYAAACKz7VmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCQ1DAZJUuP/A99FfNy/NR54AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1a569390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_val.isnull().sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1777fe10>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEuCAYAAACKz7VmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCQ1DAZJUuP/A99FfNy/NR54AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a19b17c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test.isnull().sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assuming that the y value is the prediction after 6 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_evaluate(model): \n",
    "    model.fit(X_train, y_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_train),y_true=y_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_val),y_true=y_val))\n",
    "    print(\"Train RMSE: \", train_rmse)\n",
    "    print(\"Validation RMSE: \", val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  79.7253515825\n",
      "Validation RMSE 75.7225586488\n"
     ]
    }
   ],
   "source": [
    "lm_ridge = Ridge()\n",
    "fit_evaluate(lm_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  79.7409772433\n",
      "Validation RMSE 75.7733661698\n"
     ]
    }
   ],
   "source": [
    "lm_lasso = Lasso()\n",
    "fit_evaluate(lm_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  26.2214377774\n",
      "Validation RMSE 61.2192863745\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "fit_evaluate(rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  54.9240420598\n",
      "Validation RMSE 66.1490892694\n"
     ]
    }
   ],
   "source": [
    "kn_reg = KNeighborsRegressor()\n",
    "fit_evaluate(kn_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  342.097216367\n",
      "Validation RMSE 340.793481167\n"
     ]
    }
   ],
   "source": [
    "sv_reg = SVR()\n",
    "fit_evaluate(sv_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  60.1988291462\n",
      "Validation RMSE 62.7694025553\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "fit_evaluate(gb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  94.1325517621\n",
      "Validation RMSE 96.2058734137\n"
     ]
    }
   ],
   "source": [
    "ab_reg = AdaBoostRegressor()\n",
    "fit_evaluate(ab_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discarding missing data & Repeat Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nreg_data = reg_data.dropna(how=\"any\")\n",
    "X = nreg_data.drop(['date', 'time', 'y', 'level'], axis = 1)\n",
    "y = nreg_data['y']\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=7)\n",
    "# Train validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  70.4145706828\n",
      "Validation RMSE 73.3346814294\n"
     ]
    }
   ],
   "source": [
    "lm_ridge = Ridge()\n",
    "fit_evaluate(lm_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  70.4575607478\n",
      "Validation RMSE 73.3923384891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinash/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lm_lasso = Lasso()\n",
    "fit_evaluate(lm_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  25.7376566707\n",
      "Validation RMSE 62.5477714061\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "fit_evaluate(rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  51.1340994283\n",
      "Validation RMSE 64.1751705051\n"
     ]
    }
   ],
   "source": [
    "kn_reg = KNeighborsRegressor()\n",
    "fit_evaluate(kn_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  332.364538279\n",
      "Validation RMSE 333.170333174\n"
     ]
    }
   ],
   "source": [
    "sv_reg = SVR()\n",
    "fit_evaluate(sv_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  53.4535252779\n",
      "Validation RMSE 65.3974484768\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "fit_evaluate(gb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  80.2318135482\n",
      "Validation RMSE 79.5669598433\n"
     ]
    }
   ],
   "source": [
    "ab_reg = AdaBoostRegressor()\n",
    "fit_evaluate(ab_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  53.5669636342\n",
      "Validation RMSE 64.8392549149\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = XGBRegressor()\n",
    "fit_evaluate(xgb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': np.arange(100,300,50),\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'max_depth': [None, 5, 7, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "opt_gbc = GridSearchCV(rf_reg, parameters, n_jobs = -1)\n",
    "opt_gbc.fit(X_train,y_train)\n",
    "print(opt_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  21.2269576837\n",
      "Validation RMSE 60.8176485107\n"
     ]
    }
   ],
   "source": [
    "rf_reg_opt = RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 200)\n",
    "fit_evaluate(rf_reg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'learning_rate' : np.logspace(-2,0,num=3),\n",
    "              'n_estimators': [100, 200, 250], \n",
    "              'max_depth':[3,5,7], \n",
    "              'max_features': ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.10000000000000001, 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "opt_gbc = GridSearchCV(gb_reg, parameters, n_jobs = -1)\n",
    "opt_gbc.fit(X_train,y_train)\n",
    "print(opt_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  8.56109453363\n",
      "Validation RMSE 56.9203243769\n"
     ]
    }
   ],
   "source": [
    "gb_reg_opt = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 7,\n",
    "                                       max_features = 'sqrt', n_estimators = 250)\n",
    "fit_evaluate(gb_reg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model): \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_train),y_true=y_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_val),y_true=y_val))\n",
    "    print(\"Train RMSE: \", train_rmse)\n",
    "    print(\"Validation RMSE: \", val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Extra trees regressor for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          ...       presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False))])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(ExtraTreesRegressor(n_estimators=250, random_state=7))),\n",
    "  ('classification', GradientBoostingRegressor(learning_rate = 0.1, max_depth = 7,\n",
    "                                       max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "etr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  13.7026352474\n",
      "Validation RMSE:  68.987089725\n"
     ]
    }
   ],
   "source": [
    "evaluate(etr_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Lasso for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinash/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None)),...       presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False))])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(Lasso())),\n",
    "  ('classification', GradientBoostingRegressor(learning_rate = 0.1, max_depth = 7,\n",
    "                                       max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "\n",
    "lasso_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  8.66837474098\n",
      "Validation RMSE:  56.0470304172\n"
     ]
    }
   ],
   "source": [
    "evaluate(lasso_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using LinearSVR feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVR(C=0.1, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0),\n",
       "        norm_order=1, prefit=False, threshold=None)), ('classific...       presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False))])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVR(C=0.1))),\n",
    "  ('classification', GradientBoostingRegressor(learning_rate = 0.1, max_depth = 7,\n",
    "                                       max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "\n",
    "svr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  21.9670434982\n",
      "Validation RMSE:  83.7624509286\n"
     ]
    }
   ],
   "source": [
    "evaluate(reg_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RMSE with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  50.3153802522\n"
     ]
    }
   ],
   "source": [
    "test_rmse = np.sqrt(mean_squared_error(y_pred=lasso_pipeline.predict(X_test),y_true=y_test))\n",
    "print(\"Test RMSE: \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_classifier = open(\"task2_model.pickle\", \"wb\")\n",
    "pickle.dump(lasso_pipeline, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
