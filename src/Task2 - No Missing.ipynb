{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For imputing missing values for level_binary\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for predicting\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For imputation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for hyperparameter optimization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for feature selection\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC, LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To save the final model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "reg_data = pd.read_csv(\"../results/processed_data/forecasting_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8415, 15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>y</th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-03-10T12:30:00Z</td>\n",
       "      <td>1185</td>\n",
       "      <td>2.6</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-03-10T13:30:00Z</td>\n",
       "      <td>1136</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03-10T14:30:00Z</td>\n",
       "      <td>1094</td>\n",
       "      <td>2.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-03-10T15:30:00Z</td>\n",
       "      <td>1010</td>\n",
       "      <td>2.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-03-10T16:30:00Z</td>\n",
       "      <td>1011</td>\n",
       "      <td>1.6</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time_stamp     y  co_gt   nhmc  c6h6     s2    nox      s3  \\\n",
       "0  2004-03-10T12:30:00Z  1185    2.6  150.0  11.9    NaN  166.0  1056.0   \n",
       "1  2004-03-10T13:30:00Z  1136    2.0  112.0   9.4  955.0  103.0  1174.0   \n",
       "2  2004-03-10T14:30:00Z  1094    2.2   88.0   9.0  939.0  131.0  1140.0   \n",
       "3  2004-03-10T15:30:00Z  1010    2.2   80.0   9.2  948.0  172.0  1092.0   \n",
       "4  2004-03-10T16:30:00Z  1011    1.6   51.0   6.5  836.0  131.0  1205.0   \n",
       "\n",
       "     no2      s4      s5     t    rh      ah level  \n",
       "0  113.0  1692.0     NaN  13.6  48.9  0.7578  High  \n",
       "1   92.0  1559.0   972.0  13.3  47.7  0.7255  High  \n",
       "2  114.0  1555.0  1074.0  11.9   NaN  0.7502   NaN  \n",
       "3  122.0  1584.0  1203.0  11.0  60.0  0.7867  High  \n",
       "4  116.0     NaN  1110.0   NaN  59.6  0.7888  High  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_data[\"level\"] = reg_data[\"level\"].map( {'Very low': -2, 'Low':-1, 'moderate':0, 'High':1, 'Very High':2 } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nreg_data = reg_data.dropna(how=\"any\")\n",
    "X = nreg_data.drop(['time_stamp', 'y'], axis = 1)\n",
    "y = nreg_data['y']\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=7)\n",
    "# Train validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x114424b00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEOCAYAAACNY7BQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113b3ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.isnull().sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>750.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.2</td>\n",
       "      <td>0.7848</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>690.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1333.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>56.8</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>609.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>59.7</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   co_gt   nhmc  c6h6     s2    nox      s3    no2      s4      s5     t  \\\n",
       "1    2.0  112.0   9.4  955.0  103.0  1174.0   92.0  1559.0   972.0  13.3   \n",
       "3    2.2   80.0   9.2  948.0  172.0  1092.0  122.0  1584.0  1203.0  11.0   \n",
       "5    1.2   38.0   4.7  750.0   89.0  1337.0   96.0  1393.0   949.0  11.2   \n",
       "6    1.2   31.0   3.6  690.0   62.0  1462.0   77.0  1333.0   733.0  11.3   \n",
       "8    0.9   24.0   2.3  609.0   45.0  1579.0   60.0  1276.0   620.0  10.7   \n",
       "\n",
       "     rh      ah  level  \n",
       "1  47.7  0.7255    1.0  \n",
       "3  60.0  0.7867    1.0  \n",
       "5  59.2  0.7848    1.0  \n",
       "6  56.8  0.7603    1.0  \n",
       "8  59.7  0.7648   -1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_evaluate(model): \n",
    "    '''\n",
    "    Function prints the training and validation scores.\n",
    "    Args\n",
    "        Model: Sklearn object with predict method.\n",
    "    \n",
    "    Returns\n",
    "        None\n",
    "    '''\n",
    "    model.fit(X_train, y_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_train),y_true=y_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_val),y_true=y_val))\n",
    "    print(\"Train RMSE: \", train_rmse)\n",
    "    print(\"Validation RMSE: \", val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  256.790457334\n",
      "Validation RMSE:  271.888130727\n"
     ]
    }
   ],
   "source": [
    "lm_ridge = Ridge()\n",
    "fit_evaluate(lm_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  256.858638699\n",
      "Validation RMSE:  271.827323779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinash/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lm_lasso = Lasso()\n",
    "fit_evaluate(lm_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  110.812718387\n",
      "Validation RMSE:  264.093454999\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "fit_evaluate(rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  213.507866143\n",
      "Validation RMSE:  265.653100232\n"
     ]
    }
   ],
   "source": [
    "kn_reg = KNeighborsRegressor()\n",
    "fit_evaluate(kn_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  336.693830347\n",
      "Validation RMSE:  336.099480841\n"
     ]
    }
   ],
   "source": [
    "sv_reg = SVR()\n",
    "fit_evaluate(sv_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  209.73784904\n",
      "Validation RMSE:  256.479857367\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "fit_evaluate(gb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  286.347613504\n",
      "Validation RMSE:  310.183508309\n"
     ]
    }
   ],
   "source": [
    "ab_reg = AdaBoostRegressor()\n",
    "fit_evaluate(ab_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  213.606640448\n",
      "Validation RMSE:  256.868571434\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = XGBRegressor()\n",
    "fit_evaluate(xgb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': np.arange(100,300,50),\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'max_depth': [None, 5, 7, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "opt_gbc = GridSearchCV(rf_reg, parameters, n_jobs = -1)\n",
    "opt_gbc.fit(X_train,y_train)\n",
    "print(opt_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  94.5123056442\n",
      "Validation RMSE:  252.116874184\n"
     ]
    }
   ],
   "source": [
    "rf_reg_opt = RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250)\n",
    "fit_evaluate(rf_reg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'learning_rate' : np.logspace(-2,0,num=3),\n",
    "              'n_estimators': [100, 200, 250], \n",
    "              'max_depth':[3,5,7], \n",
    "              'max_features': ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.10000000000000001, 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "opt_gbc = GridSearchCV(gb_reg, parameters, n_jobs = -1)\n",
    "opt_gbc.fit(X_train,y_train)\n",
    "print(opt_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  66.4920727855\n",
      "Validation RMSE:  253.65816563\n"
     ]
    }
   ],
   "source": [
    "gb_reg_opt = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 7,\n",
    "                                       max_features = 'sqrt', n_estimators = 200)\n",
    "fit_evaluate(gb_reg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model): \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_train),y_true=y_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_val),y_true=y_val))\n",
    "    print(\"Train RMSE: \", train_rmse)\n",
    "    print(\"Validation RMSE: \", val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Extra trees regressor for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          ...imators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(ExtraTreesRegressor(n_estimators=250, random_state=7))),\n",
    "  ('classification', RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "etr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  140.938761582\n",
      "Validation RMSE:  260.819301889\n"
     ]
    }
   ],
   "source": [
    "evaluate(etr_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Lasso for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinash/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None)),...imators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(Lasso())),\n",
    "  ('classification', RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "\n",
    "lasso_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  94.0450642082\n",
      "Validation RMSE:  250.457580599\n"
     ]
    }
   ],
   "source": [
    "evaluate(lasso_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using LinearSVR feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVR(C=0.1, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0),\n",
       "        norm_order=1, prefit=False, threshold=None)), ('classific...imators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVR(C=0.1))),\n",
    "  ('classification', RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "\n",
    "svr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  142.887876526\n",
      "Validation RMSE:  269.341636016\n"
     ]
    }
   ],
   "source": [
    "evaluate(svr_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RMSE with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  228.998407766\n"
     ]
    }
   ],
   "source": [
    "test_rmse = np.sqrt(mean_squared_error(y_pred=lasso_pipeline.predict(X_test),y_true=y_test))\n",
    "print(\"Test RMSE: \", test_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
