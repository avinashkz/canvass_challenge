{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Challenge\n",
    "\n",
    "Below are 2 data challenges that test for your ability to:\n",
    "- Wrangle/clean data to make it usable by a model\n",
    "- Figure out how to set up X's and y's for a use case, given a dataset\n",
    "- Write code to robustly preprocess data\n",
    "- Pick/design the right model, and tune hyperparameters to get the best performance\n",
    "\n",
    "You can use any programming language, model, and package to solve these problems. Let us know of any assumptions you make in your process.\n",
    "\n",
    "#### Deliverables:\n",
    "- A link to a github repository that contains:\n",
    "    - Clearly commented code that was written to solve these problems\n",
    "    - Your trained models stored in a file (`.pkl`, `.h5`, `.tar` - whatever is appropriate). The models must have `predict(X)` functions\n",
    "    - A readme file that contains:\n",
    "        - Instructions to easily access/load the above\n",
    "        - A writeup explaining any significant design decisions and your reasons for making them. \n",
    "        - If needed, a brief writeup explaining anything you are particularly proud of in your implementation that you might want us to focus on\n",
    "\n",
    "#### How we'll assess your work:\n",
    "- Accuracy/RMSE of your model when predicting on held-out data\n",
    "- How well various edge cases are handled when testing on held-out data (new column in the X data that wasn't present in the dataset given to you, new value in a categorical field that wasn't seen in the dataset given to you, NA values, to name a few)\n",
    "- Efficiency of the code. Is it easy to understand? Are the variable names descriptive? Are there any variables created that aren't used? Is redundant code replaced with function calls? Is vectorized implementation used instead of nested for loops? Are classes defined and objects created where applicable? Are packages used to perform tasks instead of implementing them from scratch?\n",
    "\n",
    "Feel free to ask questions to clarify things. There's no time limit for this exercise. In your work, I encourage you to try and showcase your talents. The more you go above and beyond what's expected, the more impressed we'll be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "`predictive_maintenance_dataset.csv` is a file that contains parameters and settings (`operational_setting_1`, `operational_setting_2`, `sensor_measurement_1`, `sensor_measurement_2`, etc.) for many wind turbines. There is a column called `unit_number` which specifies which turbine it is, and one called `status`, in which a value of 1 means the turbine broke down that day, and 0 means it didn't. Your task is to create a model that, when fed with operational settings and sensor measurements (`unit_number` and `time_stamp` will *not* be fed in), outputs 1 if the turbine will break down within the next 40 days, and 0 if not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "`forecasting_dataset.csv` is a file that contains pollution data for a city. Your task is to create a model that, when fed with columns `co_gt`, `nhmc`, `c6h6`, `s2`, `nox`, `s3`, `no2`, `s4`, `s5`, `t`, `rh`, `ah`, and `level`, predicts the value of `y` six hours later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
