{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For imputing missing values for level_binary\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for predicting\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For imputation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for hyperparameter optimization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for feature selection\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC, LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To save the final model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "reg_data = pd.read_csv(\"../results/processed_data/forecasting_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8415, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>y</th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-03-10T12:30:00Z</td>\n",
       "      <td>1185</td>\n",
       "      <td>2.6</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-03-10T13:30:00Z</td>\n",
       "      <td>1136</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03-10T14:30:00Z</td>\n",
       "      <td>1094</td>\n",
       "      <td>2.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-03-10T15:30:00Z</td>\n",
       "      <td>1010</td>\n",
       "      <td>2.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-03-10T16:30:00Z</td>\n",
       "      <td>1011</td>\n",
       "      <td>1.6</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time_stamp     y  co_gt   nhmc  c6h6     s2    nox      s3  \\\n",
       "0  2004-03-10T12:30:00Z  1185    2.6  150.0  11.9    NaN  166.0  1056.0   \n",
       "1  2004-03-10T13:30:00Z  1136    2.0  112.0   9.4  955.0  103.0  1174.0   \n",
       "2  2004-03-10T14:30:00Z  1094    2.2   88.0   9.0  939.0  131.0  1140.0   \n",
       "3  2004-03-10T15:30:00Z  1010    2.2   80.0   9.2  948.0  172.0  1092.0   \n",
       "4  2004-03-10T16:30:00Z  1011    1.6   51.0   6.5  836.0  131.0  1205.0   \n",
       "\n",
       "     no2      s4      s5     t    rh      ah level  \n",
       "0  113.0  1692.0     NaN  13.6  48.9  0.7578  High  \n",
       "1   92.0  1559.0   972.0  13.3  47.7  0.7255  High  \n",
       "2  114.0  1555.0  1074.0  11.9   NaN  0.7502   NaN  \n",
       "3  122.0  1584.0  1203.0  11.0  60.0  0.7867  High  \n",
       "4  116.0     NaN  1110.0   NaN  59.6  0.7888  High  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['co_gt', 'nhmc', 'c6h6', 's2', 'nox', 's3', 'no2', 's4', 's5', 't',\n",
       "       'rh', 'ah', 'level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.drop(labels=['time_stamp', 'y'], axis='columns').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8415, 1033, 96, 424, 401, 1220, 898, 1189, 283, 1551, 1687, 422, 751, 5919, 6]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To view the unique elements per row to see number of categorical and continuous variables\n",
    "[len(reg_data[items].unique()) for items in reg_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(X, refit = False):\n",
    "\n",
    "    fixed_values = {}\n",
    "    \n",
    "    all_data = X.loc[:, ['co_gt', 'nhmc', 'c6h6',\n",
    "                         's2', 'nox', 's3', 'no2',\n",
    "                         's4', 's5', 't','rh', 'ah',\n",
    "                         'level']].copy()\n",
    "    \n",
    "    #I have made the assumption that the difference between all the levels are the same. \n",
    "    all_data[\"level\"] = all_data[\"level\"].map( {'Very low': -2, 'Low':-1, 'Moderate':0, 'High':1, 'Very High':2 } )\n",
    "    \n",
    "    feat = [np.abs(item)[item != 1] for item in [all_data.corr()[item] for item in all_data.columns]]\n",
    "\n",
    "    for c,columns in enumerate(feat):\n",
    "\n",
    "        col_name = pd.DataFrame(columns).columns[0]\n",
    "\n",
    "        print(\"==== Processing {} ====\".format(col_name))\n",
    "\n",
    "        sorted_col = pd.DataFrame(columns).sort_values(col_name)\n",
    "\n",
    "        top_corr = sorted_col.iloc[-1].name\n",
    "        second_corr = sorted_col.iloc[-2].name\n",
    "        third_corr = sorted_col.iloc[-3].name\n",
    "\n",
    "        features = [top_corr, second_corr, third_corr]\n",
    "        \n",
    "        y = all_data.loc[:, col_name]\n",
    "        x1 = all_data.loc[:, top_corr]\n",
    "        x2 = all_data.loc[:, second_corr]\n",
    "        x3 = all_data.loc[:, third_corr]\n",
    "\n",
    "        if refit:        \n",
    "\n",
    "            print(\" \\t Fitting\")\n",
    "            for number, item in enumerate([x1, x2, x3]):   \n",
    "                X_train = item[np.invert(y.isnull() | item.isnull())].values.reshape(-1, 1)\n",
    "                y_train = y[np.invert(y.isnull() | item.isnull())]\n",
    "\n",
    "                #Select Classifier or Regression model based on the number of unique values\n",
    "                if(len(y.unique()) <= 7):\n",
    "                    rf_model = RandomForestClassifier()\n",
    "                    if y_train[0] < 1 : \n",
    "                        y_train = y_train*100\n",
    "                    y_train = y_train.astype('int')\n",
    "\n",
    "                    fixed_values[col_name] = mode(y)\n",
    "\n",
    "                else:\n",
    "                    rf_model = RandomForestRegressor()\n",
    "\n",
    "                    fixed_values[col_name] = np.mean(y)\n",
    "\n",
    "                # Fitting Random forest model\n",
    "                rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "                with open('../results/pickles/{}-{}x.pickle'.format(col_name, number), 'wb') as save_model:\n",
    "                    pickle.dump(rf_model, save_model)\n",
    "\n",
    "            with open('../results/pickles/fixed_values2.pickle', 'wb') as save_model:\n",
    "                pickle.dump(fixed_values, save_model)\n",
    "\n",
    "        print(\" \\t Imputing \\n\")\n",
    "\n",
    "        # Data missing selected feature\n",
    "        fallback_1 = y.isnull() & np.invert(x1.isnull())\n",
    "        fallback_2 = y.isnull() & x1.isnull() & np.invert(x2.isnull())\n",
    "        fallback_3 = y.isnull() & x1.isnull() &  x2.isnull() & np.invert(x3.isnull())\n",
    "        fallback_4 = y.isnull() & x1.isnull() &  x2.isnull() & x3.isnull()\n",
    "        fallbacks = [fallback_1, fallback_2, fallback_3, fallback_4]\n",
    "\n",
    "        complete_data = all_data.loc[np.invert(y.isnull())].copy()\n",
    "\n",
    "        for count, item in enumerate(fallbacks):\n",
    "            if item.sum().astype(\"bool\") & (count < 3):\n",
    "                loop_data = all_data.loc[item].copy()\n",
    "                with open('../results/pickles/{}-{}x.pickle'.format(col_name, count), 'rb') as load_model:\n",
    "                    rf_model = pickle.load(load_model)\n",
    "\n",
    "                x_data = loop_data.loc[:, features[count]].values.reshape(-1, 1)\n",
    "\n",
    "                #Predicting using Random forest model\n",
    "                y_data = rf_model.predict(x_data)\n",
    "\n",
    "                loop_data.loc[:,col_name] = y_data\n",
    "\n",
    "                complete_data = complete_data.append(loop_data)\n",
    "\n",
    "            else:\n",
    "\n",
    "                #warnings.warn(\"There are more than 3 missing values in one or more records\")\n",
    "\n",
    "                loop_data = all_data.loc[item].copy()\n",
    "\n",
    "                with open('../results/pickles/fixed_values2.pickle'.format(col_name, count), 'rb') as load_model:\n",
    "                    fixed_values = pickle.load(load_model)\n",
    "\n",
    "                # Imputing with preset values as more than 4 values are missing.\n",
    "                y_data = fixed_values[col_name]\n",
    "                loop_data.loc[:,col_name] = y_data\n",
    "                complete_data = complete_data.append(loop_data)\n",
    "\n",
    "        all_data = complete_data.copy()\n",
    "\n",
    "    all_data = all_data.sort_index()\n",
    "    \n",
    "    #Binarizing variables\n",
    "    lb = LabelBinarizer()\n",
    "    for col in all_data:\n",
    "        target = all_data[col]\n",
    "        if(len(target.unique()) <= 7):\n",
    "            binary_data = lb.fit_transform(target)\n",
    "            unique_vals = all_data[col].unique()\n",
    "            unique_vals.sort()\n",
    "            col_names = [col + '_' +str(int(item)) for item in unique_vals if item is not np.nan]\n",
    "            all_data = pd.concat([all_data, pd.DataFrame(binary_data, columns= col_names)], axis = 1)\n",
    "            all_data.drop([col], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Processing co_gt ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing nhmc ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing c6h6 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing s2 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing nox ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing s3 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing no2 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing s4 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing s5 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing t ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing rh ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing ah ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing level ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = process_data(reg_data, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level_-2</th>\n",
       "      <th>level_-1</th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.6</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>972.775376</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.000000</td>\n",
       "      <td>1038.103476</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>48.900000</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.000000</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.000000</td>\n",
       "      <td>972.000000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.000000</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>34.923929</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.000000</td>\n",
       "      <td>1203.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.6</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.000000</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1452.859605</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>9.803333</td>\n",
       "      <td>59.600000</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   co_gt   nhmc  c6h6          s2    nox      s3    no2           s4  \\\n",
       "0    2.6  150.0  11.9  972.775376  166.0  1056.0  113.0  1692.000000   \n",
       "1    2.0  112.0   9.4  955.000000  103.0  1174.0   92.0  1559.000000   \n",
       "2    2.2   88.0   9.0  939.000000  131.0  1140.0  114.0  1555.000000   \n",
       "3    2.2   80.0   9.2  948.000000  172.0  1092.0  122.0  1584.000000   \n",
       "4    1.6   51.0   6.5  836.000000  131.0  1205.0  116.0  1452.859605   \n",
       "\n",
       "            s5          t         rh      ah  level_-2  level_-1  level_0  \\\n",
       "0  1038.103476  13.600000  48.900000  0.7578         0         0        0   \n",
       "1   972.000000  13.300000  47.700000  0.7255         0         0        0   \n",
       "2  1074.000000  11.900000  34.923929  0.7502         0         0        0   \n",
       "3  1203.000000  11.000000  60.000000  0.7867         0         0        0   \n",
       "4  1110.000000   9.803333  59.600000  0.7888         0         0        0   \n",
       "\n",
       "   level_1  level_2  \n",
       "0        1        0  \n",
       "1        1        0  \n",
       "2        1        0  \n",
       "3        1        0  \n",
       "4        1        0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x112f2ba90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113055a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.isnull().sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = reg_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=7)\n",
    "\n",
    "# Train validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_evaluate(model): \n",
    "    '''\n",
    "    Function prints the training and validation scores.\n",
    "    Args\n",
    "        Model: Sklearn object with predict method.\n",
    "    \n",
    "    Returns\n",
    "        None\n",
    "    '''\n",
    "    model.fit(X_train, y_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_train),y_true=y_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_val),y_true=y_val))\n",
    "    print(\"Train RMSE: \", train_rmse)\n",
    "    print(\"Validation RMSE: \", val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  254.101282695\n",
      "Validation RMSE:  262.765394359\n"
     ]
    }
   ],
   "source": [
    "lm_ridge = Ridge()\n",
    "fit_evaluate(lm_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  254.2004603\n",
      "Validation RMSE:  262.949514994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinash/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lm_lasso = Lasso()\n",
    "fit_evaluate(lm_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  107.21900472\n",
      "Validation RMSE:  242.798547787\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "fit_evaluate(rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  208.284334222\n",
      "Validation RMSE:  268.894847743\n"
     ]
    }
   ],
   "source": [
    "kn_reg = KNeighborsRegressor()\n",
    "fit_evaluate(kn_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  338.910069572\n",
      "Validation RMSE:  347.345756098\n"
     ]
    }
   ],
   "source": [
    "sv_reg = SVR()\n",
    "fit_evaluate(sv_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  221.974210789\n",
      "Validation RMSE:  247.430033941\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "fit_evaluate(gb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  289.83016992\n",
      "Validation RMSE:  299.986877207\n"
     ]
    }
   ],
   "source": [
    "ab_reg = AdaBoostRegressor()\n",
    "fit_evaluate(ab_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  223.988838639\n",
      "Validation RMSE:  246.590412433\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = XGBRegressor()\n",
    "fit_evaluate(xgb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': np.arange(100,300,50),\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'max_depth': [None, 5, 7, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "opt_gbc = GridSearchCV(rf_reg, parameters, n_jobs = -1)\n",
    "opt_gbc.fit(X_train,y_train)\n",
    "print(opt_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  91.7865152843\n",
      "Validation RMSE:  234.277532199\n"
     ]
    }
   ],
   "source": [
    "rf_reg_opt = RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250)\n",
    "fit_evaluate(rf_reg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'learning_rate' : np.logspace(-2,0,num=3),\n",
    "              'n_estimators': [100, 200, 250], \n",
    "              'max_depth':[3,5,7], \n",
    "              'max_features': ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.10000000000000001, 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "opt_gbc = GridSearchCV(gb_reg, parameters, n_jobs = -1)\n",
    "opt_gbc.fit(X_train,y_train)\n",
    "print(opt_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  85.0183499908\n",
      "Validation RMSE:  234.518576764\n"
     ]
    }
   ],
   "source": [
    "gb_reg_opt = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 7,\n",
    "                                       max_features = 'sqrt', n_estimators = 250)\n",
    "fit_evaluate(gb_reg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model): \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_train),y_true=y_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_val),y_true=y_val))\n",
    "    print(\"Train RMSE: \", train_rmse)\n",
    "    print(\"Validation RMSE: \", val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Extra trees regressor for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          ...imators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(ExtraTreesRegressor(n_estimators=250, random_state=7))),\n",
    "  ('classification', RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "etr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  132.270682794\n",
      "Validation RMSE:  256.687751746\n"
     ]
    }
   ],
   "source": [
    "evaluate(etr_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Lasso for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinash/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None)),...imators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(Lasso())),\n",
    "  ('classification', RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "\n",
    "lasso_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  92.1024429127\n",
      "Validation RMSE:  234.752332245\n"
     ]
    }
   ],
   "source": [
    "evaluate(lasso_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using LinearSVR feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVR(C=0.1, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0),\n",
       "        norm_order=1, prefit=False, threshold=None)), ('classific...imators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVR(C=0.1))),\n",
    "  ('classification', RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "\n",
    "svr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  133.445987143\n",
      "Validation RMSE:  267.170625337\n"
     ]
    }
   ],
   "source": [
    "evaluate(svr_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RMSE with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  227.086358812\n"
     ]
    }
   ],
   "source": [
    "test_rmse = np.sqrt(mean_squared_error(y_pred=lasso_pipeline.predict(X_test),y_true=y_test))\n",
    "print(\"Test RMSE: \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_classifier = open(\"../results/pickles/task2_model.pickle\", \"wb\")\n",
    "pickle.dump(lasso_pipeline, save_classifier)\n",
    "save_classifier.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
