{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For imputing missing values for level_binary\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for predicting\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For imputation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for hyperparameter optimization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries for feature selection\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC, LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To save the final model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "reg_data = pd.read_csv(\"../results/processed_data/forecasting_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8415, 15)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>y</th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-03-10T12:30:00Z</td>\n",
       "      <td>1185</td>\n",
       "      <td>2.6</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-03-10T13:30:00Z</td>\n",
       "      <td>1136</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03-10T14:30:00Z</td>\n",
       "      <td>1094</td>\n",
       "      <td>2.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-03-10T15:30:00Z</td>\n",
       "      <td>1010</td>\n",
       "      <td>2.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-03-10T16:30:00Z</td>\n",
       "      <td>1011</td>\n",
       "      <td>1.6</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004-03-10T17:30:00Z</td>\n",
       "      <td>1066</td>\n",
       "      <td>1.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>750.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.2</td>\n",
       "      <td>0.7848</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004-03-10T18:30:00Z</td>\n",
       "      <td>1052</td>\n",
       "      <td>1.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>690.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1333.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>56.8</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time_stamp     y  co_gt   nhmc  c6h6     s2    nox      s3  \\\n",
       "0  2004-03-10T12:30:00Z  1185    2.6  150.0  11.9    NaN  166.0  1056.0   \n",
       "1  2004-03-10T13:30:00Z  1136    2.0  112.0   9.4  955.0  103.0  1174.0   \n",
       "2  2004-03-10T14:30:00Z  1094    2.2   88.0   9.0  939.0  131.0  1140.0   \n",
       "3  2004-03-10T15:30:00Z  1010    2.2   80.0   9.2  948.0  172.0  1092.0   \n",
       "4  2004-03-10T16:30:00Z  1011    1.6   51.0   6.5  836.0  131.0  1205.0   \n",
       "5  2004-03-10T17:30:00Z  1066    1.2   38.0   4.7  750.0   89.0  1337.0   \n",
       "6  2004-03-10T18:30:00Z  1052    1.2   31.0   3.6  690.0   62.0  1462.0   \n",
       "\n",
       "     no2      s4      s5     t    rh      ah level  \n",
       "0  113.0  1692.0     NaN  13.6  48.9  0.7578  High  \n",
       "1   92.0  1559.0   972.0  13.3  47.7  0.7255  High  \n",
       "2  114.0  1555.0  1074.0  11.9   NaN  0.7502   NaN  \n",
       "3  122.0  1584.0  1203.0  11.0  60.0  0.7867  High  \n",
       "4  116.0     NaN  1110.0   NaN  59.6  0.7888  High  \n",
       "5   96.0  1393.0   949.0  11.2  59.2  0.7848  High  \n",
       "6   77.0  1333.0   733.0  11.3  56.8  0.7603  High  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['co_gt', 'nhmc', 'c6h6', 's2', 'nox', 's3', 'no2', 's4', 's5', 't',\n",
       "       'rh', 'ah', 'level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.drop(labels=['time_stamp', 'y'], axis='columns').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8415, 1033, 96, 424, 401, 1220, 898, 1189, 283, 1551, 1687, 422, 751, 5919, 6]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To view the unique elements per row to see number of categorical and continuous variables\n",
    "[len(reg_data[items].unique()) for items in reg_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039309</td>\n",
       "      <td>0.085769</td>\n",
       "      <td>0.629776</td>\n",
       "      <td>0.481713</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.322890</td>\n",
       "      <td>-0.047727</td>\n",
       "      <td>0.510916</td>\n",
       "      <td>0.469594</td>\n",
       "      <td>0.585893</td>\n",
       "      <td>0.622736</td>\n",
       "      <td>0.621848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co_gt</th>\n",
       "      <td>-0.039309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144904</td>\n",
       "      <td>-0.042043</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>0.528105</td>\n",
       "      <td>-0.076844</td>\n",
       "      <td>0.673869</td>\n",
       "      <td>-0.060860</td>\n",
       "      <td>0.070999</td>\n",
       "      <td>-0.075171</td>\n",
       "      <td>-0.054971</td>\n",
       "      <td>-0.056485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nhmc</th>\n",
       "      <td>0.085769</td>\n",
       "      <td>0.144904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045246</td>\n",
       "      <td>0.118003</td>\n",
       "      <td>0.010115</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.125371</td>\n",
       "      <td>0.160164</td>\n",
       "      <td>0.110891</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>0.025222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c6h6</th>\n",
       "      <td>0.629776</td>\n",
       "      <td>-0.042043</td>\n",
       "      <td>0.045246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780077</td>\n",
       "      <td>-0.018666</td>\n",
       "      <td>0.536487</td>\n",
       "      <td>-0.024913</td>\n",
       "      <td>0.801557</td>\n",
       "      <td>0.657119</td>\n",
       "      <td>0.972014</td>\n",
       "      <td>0.932765</td>\n",
       "      <td>0.986001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>0.481713</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>0.118003</td>\n",
       "      <td>0.780077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310853</td>\n",
       "      <td>-0.046816</td>\n",
       "      <td>0.169804</td>\n",
       "      <td>0.882078</td>\n",
       "      <td>0.915267</td>\n",
       "      <td>0.675398</td>\n",
       "      <td>0.615810</td>\n",
       "      <td>0.669513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nox</th>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.528105</td>\n",
       "      <td>0.010115</td>\n",
       "      <td>-0.018666</td>\n",
       "      <td>0.310853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.417388</td>\n",
       "      <td>0.815840</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>0.442418</td>\n",
       "      <td>-0.152439</td>\n",
       "      <td>-0.064128</td>\n",
       "      <td>-0.112815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>0.322890</td>\n",
       "      <td>-0.076844</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.536487</td>\n",
       "      <td>-0.046816</td>\n",
       "      <td>-0.417388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.234965</td>\n",
       "      <td>0.155247</td>\n",
       "      <td>-0.172805</td>\n",
       "      <td>0.599415</td>\n",
       "      <td>0.600389</td>\n",
       "      <td>0.642615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no2</th>\n",
       "      <td>-0.047727</td>\n",
       "      <td>0.673869</td>\n",
       "      <td>0.125371</td>\n",
       "      <td>-0.024913</td>\n",
       "      <td>0.169804</td>\n",
       "      <td>0.815840</td>\n",
       "      <td>-0.234965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010469</td>\n",
       "      <td>0.239083</td>\n",
       "      <td>-0.091683</td>\n",
       "      <td>-0.092999</td>\n",
       "      <td>-0.074792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>0.510916</td>\n",
       "      <td>-0.060860</td>\n",
       "      <td>0.160164</td>\n",
       "      <td>0.801557</td>\n",
       "      <td>0.882078</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>0.155247</td>\n",
       "      <td>-0.010469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735408</td>\n",
       "      <td>0.775042</td>\n",
       "      <td>0.677068</td>\n",
       "      <td>0.729458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>0.469594</td>\n",
       "      <td>0.070999</td>\n",
       "      <td>0.110891</td>\n",
       "      <td>0.657119</td>\n",
       "      <td>0.915267</td>\n",
       "      <td>0.442418</td>\n",
       "      <td>-0.172805</td>\n",
       "      <td>0.239083</td>\n",
       "      <td>0.735408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513154</td>\n",
       "      <td>0.548443</td>\n",
       "      <td>0.543252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.585893</td>\n",
       "      <td>-0.075171</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.972014</td>\n",
       "      <td>0.675398</td>\n",
       "      <td>-0.152439</td>\n",
       "      <td>0.599415</td>\n",
       "      <td>-0.091683</td>\n",
       "      <td>0.775042</td>\n",
       "      <td>0.513154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891316</td>\n",
       "      <td>0.982496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rh</th>\n",
       "      <td>0.622736</td>\n",
       "      <td>-0.054971</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>0.932765</td>\n",
       "      <td>0.615810</td>\n",
       "      <td>-0.064128</td>\n",
       "      <td>0.600389</td>\n",
       "      <td>-0.092999</td>\n",
       "      <td>0.677068</td>\n",
       "      <td>0.548443</td>\n",
       "      <td>0.891316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ah</th>\n",
       "      <td>0.621848</td>\n",
       "      <td>-0.056485</td>\n",
       "      <td>0.025222</td>\n",
       "      <td>0.986001</td>\n",
       "      <td>0.669513</td>\n",
       "      <td>-0.112815</td>\n",
       "      <td>0.642615</td>\n",
       "      <td>-0.074792</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.543252</td>\n",
       "      <td>0.982496</td>\n",
       "      <td>0.950516</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y     co_gt      nhmc      c6h6        s2       nox        s3  \\\n",
       "y      1.000000 -0.039309  0.085769  0.629776  0.481713  0.010667  0.322890   \n",
       "co_gt -0.039309  1.000000  0.144904 -0.042043  0.028237  0.528105 -0.076844   \n",
       "nhmc   0.085769  0.144904  1.000000  0.045246  0.118003  0.010115  0.041817   \n",
       "c6h6   0.629776 -0.042043  0.045246  1.000000  0.780077 -0.018666  0.536487   \n",
       "s2     0.481713  0.028237  0.118003  0.780077  1.000000  0.310853 -0.046816   \n",
       "nox    0.010667  0.528105  0.010115 -0.018666  0.310853  1.000000 -0.417388   \n",
       "s3     0.322890 -0.076844  0.041817  0.536487 -0.046816 -0.417388  1.000000   \n",
       "no2   -0.047727  0.673869  0.125371 -0.024913  0.169804  0.815840 -0.234965   \n",
       "s4     0.510916 -0.060860  0.160164  0.801557  0.882078  0.024722  0.155247   \n",
       "s5     0.469594  0.070999  0.110891  0.657119  0.915267  0.442418 -0.172805   \n",
       "t      0.585893 -0.075171  0.002704  0.972014  0.675398 -0.152439  0.599415   \n",
       "rh     0.622736 -0.054971  0.018850  0.932765  0.615810 -0.064128  0.600389   \n",
       "ah     0.621848 -0.056485  0.025222  0.986001  0.669513 -0.112815  0.642615   \n",
       "\n",
       "            no2        s4        s5         t        rh        ah  \n",
       "y     -0.047727  0.510916  0.469594  0.585893  0.622736  0.621848  \n",
       "co_gt  0.673869 -0.060860  0.070999 -0.075171 -0.054971 -0.056485  \n",
       "nhmc   0.125371  0.160164  0.110891  0.002704  0.018850  0.025222  \n",
       "c6h6  -0.024913  0.801557  0.657119  0.972014  0.932765  0.986001  \n",
       "s2     0.169804  0.882078  0.915267  0.675398  0.615810  0.669513  \n",
       "nox    0.815840  0.024722  0.442418 -0.152439 -0.064128 -0.112815  \n",
       "s3    -0.234965  0.155247 -0.172805  0.599415  0.600389  0.642615  \n",
       "no2    1.000000 -0.010469  0.239083 -0.091683 -0.092999 -0.074792  \n",
       "s4    -0.010469  1.000000  0.735408  0.775042  0.677068  0.729458  \n",
       "s5     0.239083  0.735408  1.000000  0.513154  0.548443  0.543252  \n",
       "t     -0.091683  0.775042  0.513154  1.000000  0.891316  0.982496  \n",
       "rh    -0.092999  0.677068  0.548443  0.891316  1.000000  0.950516  \n",
       "ah    -0.074792  0.729458  0.543252  0.982496  0.950516  1.000000  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(X, refit = False):\n",
    "\n",
    "    fixed_values = {}\n",
    "    \n",
    "    all_data = X.loc[:, ['co_gt', 'nhmc', 'c6h6',\n",
    "                         's2', 'nox', 's3', 'no2',\n",
    "                         's4', 's5', 't','rh', 'ah',\n",
    "                         'level']].copy()\n",
    "    \n",
    "    #I have made the assumption that the difference between all the levels are the same. \n",
    "    all_data[\"level\"] = all_data[\"level\"].map( {'Very low': -2, 'Low':-1, 'moderate':0, 'High':1, 'Very High':2 } )\n",
    "    \n",
    "    feat = [np.abs(item)[item != 1] for item in [all_data.corr()[item] for item in all_data.columns]]\n",
    "\n",
    "    for c,columns in enumerate(feat):\n",
    "\n",
    "        col_name = pd.DataFrame(columns).columns[0]\n",
    "\n",
    "        print(\"==== Processing {} ====\".format(col_name))\n",
    "\n",
    "        top_corr = np.argmax(np.abs(columns))\n",
    "        second_corr = pd.DataFrame(columns).sort_values(col_name).iloc[-2].name\n",
    "        third_corr = pd.DataFrame(columns).sort_values(col_name).iloc[-3].name\n",
    "\n",
    "        features = [top_corr, second_corr, third_corr]\n",
    "        \n",
    "        y = all_data.loc[:, col_name]\n",
    "        x1 = all_data.loc[:, top_corr]\n",
    "        x2 = all_data.loc[:, second_corr]\n",
    "        x3 = all_data.loc[:, third_corr]\n",
    "\n",
    "        if refit:        \n",
    "\n",
    "            print(\" \\t Fitting\")\n",
    "            for number, item in enumerate([x1, x2, x3]):   \n",
    "                X_train = item[np.invert(y.isnull() | item.isnull())].values.reshape(-1, 1)\n",
    "                y_train = y[np.invert(y.isnull() | item.isnull())]\n",
    "\n",
    "                #Select Classifier or Regression model based on the number of unique values\n",
    "                if(len(y.unique()) <= 7):\n",
    "                    rf_model = RandomForestClassifier()\n",
    "                    if y_train[0] < 1 : \n",
    "                        y_train = y_train*100\n",
    "                    y_train = y_train.astype('int')\n",
    "\n",
    "                    fixed_values[col_name] = mode(y)\n",
    "\n",
    "                else:\n",
    "                    rf_model = RandomForestRegressor()\n",
    "\n",
    "                    fixed_values[col_name] = np.mean(y)\n",
    "\n",
    "                # Fitting Random forest model\n",
    "                rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "                with open('../results/pickles/{}-{}x.pickle'.format(col_name, number), 'wb') as save_model:\n",
    "                    pickle.dump(rf_model, save_model)\n",
    "\n",
    "            with open('../results/pickles/fixed_values2.pickle', 'wb') as save_model:\n",
    "                pickle.dump(fixed_values, save_model)\n",
    "\n",
    "        print(\" \\t Imputing \\n\")\n",
    "\n",
    "        # Data missing selected feature\n",
    "        fallback_1 = y.isnull() & np.invert(x1.isnull())\n",
    "        fallback_2 = y.isnull() & x1.isnull() & np.invert(x2.isnull())\n",
    "        fallback_3 = y.isnull() & x1.isnull() &  x2.isnull() & np.invert(x3.isnull())\n",
    "        fallback_4 = y.isnull() & x1.isnull() &  x2.isnull() & x3.isnull()\n",
    "        fallbacks = [fallback_1, fallback_2, fallback_3, fallback_4]\n",
    "\n",
    "        complete_data = all_data.loc[np.invert(y.isnull())].copy()\n",
    "\n",
    "        for count, item in enumerate(fallbacks):\n",
    "            if item.sum().astype(\"bool\") & (count < 3):\n",
    "                loop_data = all_data.loc[item].copy()\n",
    "                with open('../results/pickles/{}-{}x.pickle'.format(col_name, count), 'rb') as load_model:\n",
    "                    rf_model = pickle.load(load_model)\n",
    "\n",
    "                x_data = loop_data.loc[:, features[count]].values.reshape(-1, 1)\n",
    "\n",
    "                #Predicting using Random forest model\n",
    "                y_data = rf_model.predict(x_data)\n",
    "\n",
    "                loop_data.loc[:,col_name] = y_data\n",
    "\n",
    "                complete_data = complete_data.append(loop_data)\n",
    "\n",
    "            else:\n",
    "\n",
    "                #warnings.warn(\"There are more than 3 missing values in one or more records\")\n",
    "\n",
    "                loop_data = all_data.loc[item].copy()\n",
    "\n",
    "                with open('../results/pickles/fixed_values2.pickle'.format(col_name, count), 'rb') as load_model:\n",
    "                    fixed_values = pickle.load(load_model)\n",
    "\n",
    "                # Imputing with preset values as more than 4 values are missing.\n",
    "                y_data = fixed_values[col_name]\n",
    "                loop_data.loc[:,col_name] = y_data\n",
    "                complete_data = complete_data.append(loop_data)\n",
    "\n",
    "        all_data = complete_data.copy()\n",
    "\n",
    "    all_data = all_data.sort_index()\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Processing co_gt ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing nhmc ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing c6h6 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing s2 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing nox ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing s3 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing no2 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing s4 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing s5 ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing t ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing rh ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing ah ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n",
      "==== Processing level ====\n",
      " \t Fitting\n",
      " \t Imputing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = process_data(reg_data, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a52d23eb8>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEOCAYAAACNY7BQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a522706a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.isnull().sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.6</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>950.255</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.000000</td>\n",
       "      <td>971.239048</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>48.900</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.000</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.000000</td>\n",
       "      <td>972.000000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>47.700</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.000</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>25.325</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.000</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.000000</td>\n",
       "      <td>1203.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.6</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.000</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1483.187727</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>9.803333</td>\n",
       "      <td>59.600</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   co_gt   nhmc  c6h6       s2    nox      s3    no2           s4  \\\n",
       "0    2.6  150.0  11.9  950.255  166.0  1056.0  113.0  1692.000000   \n",
       "1    2.0  112.0   9.4  955.000  103.0  1174.0   92.0  1559.000000   \n",
       "2    2.2   88.0   9.0  939.000  131.0  1140.0  114.0  1555.000000   \n",
       "3    2.2   80.0   9.2  948.000  172.0  1092.0  122.0  1584.000000   \n",
       "4    1.6   51.0   6.5  836.000  131.0  1205.0  116.0  1483.187727   \n",
       "\n",
       "            s5          t      rh      ah  level  \n",
       "0   971.239048  13.600000  48.900  0.7578    1.0  \n",
       "1   972.000000  13.300000  47.700  0.7255    1.0  \n",
       "2  1074.000000  11.900000  25.325  0.7502    1.0  \n",
       "3  1203.000000  11.000000  60.000  0.7867    1.0  \n",
       "4  1110.000000   9.803333  59.600  0.7888    1.0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = reg_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=7)\n",
    "\n",
    "# Train validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_evaluate(model): \n",
    "    '''\n",
    "    Function prints the training and validation scores.\n",
    "    Args\n",
    "        Model: Sklearn object with predict method.\n",
    "    \n",
    "    Returns\n",
    "        None\n",
    "    '''\n",
    "    model.fit(X_train, y_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_train),y_true=y_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_val),y_true=y_val))\n",
    "    print(\"Train RMSE: \", train_rmse)\n",
    "    print(\"Validation RMSE: \", val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  254.277993216\n",
      "Validation RMSE:  262.56139351\n"
     ]
    }
   ],
   "source": [
    "lm_ridge = Ridge()\n",
    "fit_evaluate(lm_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  254.28443515\n",
      "Validation RMSE:  262.594973092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinash/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lm_lasso = Lasso()\n",
    "fit_evaluate(lm_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  107.700887652\n",
      "Validation RMSE:  245.156060304\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "fit_evaluate(rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  208.644164468\n",
      "Validation RMSE:  266.539769986\n"
     ]
    }
   ],
   "source": [
    "kn_reg = KNeighborsRegressor()\n",
    "fit_evaluate(kn_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  338.92411898\n",
      "Validation RMSE:  347.355668663\n"
     ]
    }
   ],
   "source": [
    "sv_reg = SVR()\n",
    "fit_evaluate(sv_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  222.03976704\n",
      "Validation RMSE:  247.632489335\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "fit_evaluate(gb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  308.360881283\n",
      "Validation RMSE:  318.74543767\n"
     ]
    }
   ],
   "source": [
    "ab_reg = AdaBoostRegressor()\n",
    "fit_evaluate(ab_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  223.744786707\n",
      "Validation RMSE:  246.675579883\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = XGBRegressor()\n",
    "fit_evaluate(xgb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': np.arange(100,300,50),\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'max_depth': [None, 5, 7, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "opt_gbc = GridSearchCV(rf_reg, parameters, n_jobs = -1)\n",
    "opt_gbc.fit(X_train,y_train)\n",
    "print(opt_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  91.7865152843\n",
      "Validation RMSE:  234.277532199\n"
     ]
    }
   ],
   "source": [
    "rf_reg_opt = RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250)\n",
    "fit_evaluate(rf_reg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'learning_rate' : np.logspace(-2,0,num=3),\n",
    "              'n_estimators': [100, 200, 250], \n",
    "              'max_depth':[3,5,7], \n",
    "              'max_features': ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.10000000000000001, 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "opt_gbc = GridSearchCV(gb_reg, parameters, n_jobs = -1)\n",
    "opt_gbc.fit(X_train,y_train)\n",
    "print(opt_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  85.0183499908\n",
      "Validation RMSE:  234.518576764\n"
     ]
    }
   ],
   "source": [
    "gb_reg_opt = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 7,\n",
    "                                       max_features = 'sqrt', n_estimators = 250)\n",
    "fit_evaluate(gb_reg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model): \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_train),y_true=y_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_pred=model.predict(X_val),y_true=y_val))\n",
    "    print(\"Train RMSE: \", train_rmse)\n",
    "    print(\"Validation RMSE: \", val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Extra trees regressor for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          ...imators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(ExtraTreesRegressor(n_estimators=250, random_state=7))),\n",
    "  ('classification', RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "etr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  132.270682794\n",
      "Validation RMSE:  256.687751746\n"
     ]
    }
   ],
   "source": [
    "evaluate(etr_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Lasso for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinash/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None)),...imators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(Lasso())),\n",
    "  ('classification', RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "\n",
    "lasso_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  92.1024429127\n",
      "Validation RMSE:  234.752332245\n"
     ]
    }
   ],
   "source": [
    "evaluate(lasso_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using LinearSVR feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVR(C=0.1, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0),\n",
       "        norm_order=1, prefit=False, threshold=None)), ('classific...imators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_pipeline = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVR(C=0.1))),\n",
    "  ('classification', RandomForestRegressor(max_depth = None, max_features = 'sqrt', n_estimators = 250))\n",
    "])\n",
    "\n",
    "svr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  133.445987143\n",
      "Validation RMSE:  267.170625337\n"
     ]
    }
   ],
   "source": [
    "evaluate(svr_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RMSE with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  227.086358812\n"
     ]
    }
   ],
   "source": [
    "test_rmse = np.sqrt(mean_squared_error(y_pred=lasso_pipeline.predict(X_test),y_true=y_test))\n",
    "print(\"Test RMSE: \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_classifier = open(\"../results/pickles/task2_model.pickle\", \"wb\")\n",
    "pickle.dump(lasso_pipeline, save_classifier)\n",
    "save_classifier.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
